---
title: "Code for Master Thesis Project"
author: "Alessio Valente"
date: '2022-06-29'
output:
  html_document: default
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Analytics model for price prediction of airline stocks price based on airlines' operational metrics

```{r Libraries, warnings=FALSE}

suppressMessages(library(readxl))
suppressMessages(library(plyr))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
suppressMessages(library(readr))
suppressMessages(library(corrplot))
suppressMessages(library(plm))
suppressMessages(library(caret))
suppressMessages(library(tidyverse))
suppressMessages(library(VIM))
suppressMessages(library(doParallel))
suppressMessages(library(neuralnet))
suppressMessages(library(randomForest))
set.seed(1908)

```

We begin by importing the data which was collected in separated files for each company. A first process of data formatting and reorganization has been carried out from the Eikon data. 

```{r Import Data, warnings=FALSE}

Files <- c("Data/Aeroflot.csv", "Data/AirFrance_KLM.csv", "Data/Alaska_Air.csv", "Data/American_Airlines.csv", "Data/Delta.csv", "Data/Easyjet.csv", "Data/International_Airline_Group.csv", "Data/Jetblue.csv", "Data/Lufthansa.csv", "Data/Norwegian.csv", "Data/Ryanair.csv", "Data/Scandinavian.csv", "Data/Southwest.csv", "Data/Spirit.csv", "Data/Turkish.csv", "Data/United_Airlines.csv", "Data/WizzAir.csv")


Full_data = suppressMessages(do.call(rbind.fill, lapply(Files, function(x) read_delim(x,  delim = ";", na = "N/A",))))

airline_names <- gsub("Data/", "", Files)
airline_names <- gsub("\\.csv$", "", airline_names)

#Let us now check for data integrity and correct formatting

Full_data$EU <- as.factor(Full_data$EU)
Full_data$US <- as.factor(Full_data$US)
Full_data$Low_cost <- as.factor(Full_data$Low_cost)

#Reorganizing columns and dropping empty ones
my_columns <- as.list(colnames(Full_data))
Full_data$Break_even_load_factor <- NULL
Full_data$Revenue_per_employee <- NULL
Full_data[,69] <- NULL #Total_breakeven_load_factor_%
#summary(Full_data)

col_order <- c( 1, 61, 62, 63, 64, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 2, 3, 4, 5, 6, 7, 8, 9, 43, 44, 45, 46, 47, 48, 49, 50, 51 , 52, 53, 54, 55, 56, 57, 58, 66, 67, 68, 69, 70, 71, 72, 59, 60, 65) #reorganizing to have financial metrics on one side and operating metrics on the other
Full_data <- Full_data[, col_order]
my_columns <- as.list(colnames(Full_data))

colnames(Full_data)[71] <- "Percentage_change"
Full_data$N_planes <- NULL #Equal to Fleet_size

#Given the high number of NAs column, we will try to impute as much values as it's feasible and dropping the unfeasible variables.

#The column "Effective_tax_rate" has been imputed manually by using the last previously available number
#The column "N_Planes" has been imputed manually by using the last previously available number
#The column "Fleet_size" has been imputed manually by using the last previously available number

```

Let us apply some data processing techniques to ensure model efficacy

```{r Models data preparation, warnings=FALSE}

#Before starting with the model, let's adjust for highly correlated variables
model_data <- Full_data

model_data <- model_data[colSums(is.na(model_data)) < 190]

model_data <- model_data %>% drop_na(.)
model_data$Airline <- NULL
model_data$Net <- NULL
model_data$Percentage_change <- NULL
model_data$Period <- NULL
model_data$US <- NULL
#summary(model_data)

model_data_corr <- cor(model_data[,3:35])
hc = findCorrelation(model_data_corr, cutoff=0.9)
hc = sort(hc)
model_data = model_data[,-c(hc+2)]

detect.lindep(model_data)

# Variables correlation plot - save image
file_path= "Correlation matrix.png"
png(height=1240, width=1240, file=file_path, type = "cairo")

corrplot(model_data_corr,
         method='color',
         type="upper",
         main="Correlation among model variables",
         sig.level = 0.01,
         insig = "blank",
         mar = c(0,0,1,0), 
         number.cex = 0.5, 
         number.digits = 2
         )
dev.off()

```

Let us now start with the model estimation

```{r Models first test, warnings=FALSE}

# First, let's allow for parallel computing
cores <- detectCores()
cluster <- makePSOCKcluster(cores -1)
registerDoParallel(cluster)
start <- Sys.time()
set.seed(1908)

#split the data in train and test

samp <- createDataPartition(model_data$Close_price, p = 0.8, list = FALSE)
training <- model_data[samp,]
testing <- model_data[-samp,]

#carry out a model prediction of "Close_price" based on the other variables

#Simple Regression model

lm_model <- train(Close_price~.,
                  data = training,
                  method="lm") #lm model
predict_lm <- predict(lm_model, testing)
lm_results <- postResample(pred = predict_lm, obs = testing$Close_price)

#Elastic Net model (summarizes features of Lasso and Ridge models)

grid <- 10^seq(10,-2,length=100)
elnet_grid <- expand.grid(alpha = seq(0,1,0.1), 
                          lambda = grid)
cv_10 <- trainControl(method = "cv", number = 10)

elnet_model = train(
  Close_price ~ .,
  data = training,
  method = "glmnet",
  trControl = cv_10,
  tuneGrid = elnet_grid
)

predict_elnet <- predict(elnet_model, testing)
elnet_results <- postResample(pred = predict_elnet, obs = testing$Close_price)

# Random Forest model

rf_model <- train(Close_price~.,
                  data = training,
                  method = "rf",
                  metric = "Rsquared",
                  trControl = trainControl(method = "cv", number = 10)
                  ) # random forest model

predict_rf <- predict(rf_model, testing)
rf_results <- postResample(pred = predict_rf, obs = testing$Close_price)

# Deep Neural Network model

col_names_preprocess <- colnames(training)

pre_train <- as.data.frame(matrix(nrow=nrow(training),ncol=ncol(training)))
pre_train[,3:25] <- training[,3:25]
preProcValues_train <- preProcess(pre_train, method = "range")
pre_train <- predict(preProcValues_train, pre_train) 
pre_train[,1:2] <- training[,1:2]
colnames(pre_train) <- col_names_preprocess

pre_test <- as.data.frame(matrix(nrow=nrow(testing),ncol=ncol(testing)))
pre_test[,3:25] <- testing[,3:25]
preProcValues_test <- preProcess(pre_test, method = "range")
pre_test <- predict(preProcValues_test, pre_test) 
pre_test[,1:2] <- testing[,1:2]
colnames(pre_test) <- col_names_preprocess


deep_grid <- expand.grid(layer1 = 1:10, layer2 = 1:10, layer3 = 1:10)

deep_net <- train(Close_price ~ ., 
                  data = pre_train,
                  method = "neuralnet",
                  trControl = trainControl(method = "cv", number = 10),
                  tuneGrid = deep_grid
)

pred_deep_pre <- predict(deep_net, pre_test)

pred_deep <- pred_deep_pre * 
  (max(training$Close_price) - min(training$Close_price)) + min(training$Close_price)

deep_net_results <- postResample(pred = pred_deep, obs = testing$Close_price)

#Stopping timing
end <- Sys.time()
(time <- end - start)

#selection of best model

print("The simple linear regression model's performances are: ")
lm_results
print("The elastic net model's performances are: ")
elnet_results
print("The random forest model's performances are: ")
rf_results
print("The deep network model's performances are: ")
deep_net_results


```

Let us then test model power when training the models with the log(Closing_price) instead of Closing Price

```{r Models log test, warnings=FALSE}

model_data$Close_price <- log(model_data$Close_price)
colnames(model_data)[25] <- "Log_close_price"

# Set seed and start counting time
start <- Sys.time()
set.seed(1908)

#split the data in train and test

log_training <- model_data[samp,]
log_testing <- model_data[-samp,]

#carry out a model prediction of "Log_close_price" based on the other variables

#Simple Regression model

lm_log_model <- train(Log_close_price~.,
                  data = log_training,
                  method="lm") #lm model
predict_log_lm <- predict(lm_log_model, log_testing)
lm_log_results <- postResample(pred = exp(predict_log_lm), obs = exp(log_testing$Log_close_price))

#Elastic Net model (summarizes features of Lasso and Ridge models)

grid <- 10^seq(10,-2,length=100)
elnet_grid <- expand.grid(alpha = seq(0,1,0.1), 
                          lambda = grid)
cv_10 <- trainControl(method = "cv", number = 10)

elnet_log_model = train(
  Log_close_price ~ .,
  data = log_training,
  method = "glmnet",
  trControl = cv_10,
  tuneGrid = elnet_grid
)

predict_log_elnet <- predict(elnet_log_model, log_testing)
elnet_log_results <- postResample(pred = exp(predict_log_elnet), obs = exp(log_testing$Log_close_price))

# Random Forest model

rf_log_model <- train(Log_close_price~.,
                  data = log_training,
                  method="rf",
                  metric = "Rsquared",
                  trControl = trainControl(method = "cv", number = 10)
                  ) # random forest model

predict_log_rf <- predict(rf_log_model, log_testing)
rf_log_results <- postResample(pred = exp(predict_log_rf), obs = exp(log_testing$Log_close_price))

# Deep Neural Network model

col_names_preprocess <- colnames(log_training)

pre_train <- as.data.frame(matrix(nrow=nrow(log_training),ncol=ncol(log_training)))
pre_train[,3:25] <- log_training[,3:25]
preProcValues_train <- preProcess(pre_train, method = "range")
pre_train <- predict(preProcValues_train, pre_train) 
pre_train[,1:2] <- log_training[,1:2]
colnames(pre_train) <- col_names_preprocess

pre_test <- as.data.frame(matrix(nrow=nrow(testing),ncol=ncol(log_testing)))
pre_test[,3:25] <- log_testing[,3:25]
preProcValues_test <- preProcess(pre_test, method = "range")
pre_test <- predict(preProcValues_test, pre_test) 
pre_test[,1:2] <- log_testing[,1:2]
colnames(pre_test) <- col_names_preprocess

deep_net_log <- train(Log_close_price ~ ., 
                  data = pre_train,
                  method = "neuralnet",
                  trControl = trainControl(method = "cv", number = 10),
                  tuneGrid = deep_grid
)

pred_deep_pre_log <- predict(deep_net_log, pre_test)

pred_deep_log <- pred_deep_pre_log * 
  (max(log_training$Log_close_price) - min(log_training$Log_close_price)) + min(log_training$Log_close_price)

deep_net_log_results <- postResample(pred = exp(pred_deep_log), obs = exp(log_testing$Log_close_price))

#Stop counting time
end <- Sys.time()
(time <- end - start)

#selection of best model

print("The simple linear regression model's performances (with log prices training) are: ")
lm_log_results
print("The elastic net model's performances (with log prices training) are: ")
elnet_log_results
print("The random forest model's performances (with log prices training) are: ")
rf_log_results
print("The deep network model's performances (with log prices training) are: ")
deep_net_log_results


```

After having selected the best model, and confirmed that the log_close_price is a better variable for model training, let us perform the following test as verification to our hypothesis:

1) we will separate the financial variables and the operating variables
2) test the Random Forest model efficacy first with financial, then operating, and then both sets of variables
3) verify results against hypothesis

```{r Separation of variables - random forest model test, warnings=FALSE}
# Set seed and start counting time
start <- Sys.time()
set.seed(1908)

financial_test_data <- model_data[,c(1:18,25)]
operating_test_data <- model_data[,c(1,2,19:25)]

fit_control <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)

#Fin variables test

training_fin <- financial_test_data[samp,]
testing_fin <- financial_test_data[-samp,]

model_fin <- train(Log_close_price ~ . ,
                   data = training_fin,
                   method="rf",
                   trControl = fit_control,
                   metric = "Rsquared"
                   ) #rf model
predict_rf_fin <- predict(model_fin, testing_fin)
Fin_var_rf_results <- postResample(pred = exp(predict_rf_fin), obs = exp(testing_fin$Log_close_price))

#Operating variables test

training_op <- operating_test_data[samp,]
testing_op <- operating_test_data[-samp,]

model_op <- train(Log_close_price ~ . ,
                  data = training_op,
                  method="rf",
                  trControl = fit_control,
                  metric = "Rsquared"
                  ) #rf model
predict_rf_op <- predict(model_op, testing_op)
Op_var_rf_results <- postResample(pred = exp(predict_rf_op), obs = exp(testing_op$Log_close_price))

#Full variable combination test

training <- model_data[samp,]
testing <- model_data[-samp,]

model_all <- train(Log_close_price~.,
                   data = training,
                   method="rf",
                   trControl = fit_control,
                   metric = "Rsquared"
                   ) #rf model
predict_rf <- predict(model_all, testing)
All_var_rf_results <- postResample(pred = exp(predict_rf), obs = exp(testing$Log_close_price))

Fin_var_rf_results
Op_var_rf_results
All_var_rf_results

#Stop counting time
end <- Sys.time()
(time <- end - start)

```

Now, the same procedure for the linear regression model

```{r Separation of variables - lm model test, warnings=FALSE}
# Set seed and start counting time
start <- Sys.time()
set.seed(1908)

financial_test_data <- model_data[,c(1:18,25)]
operating_test_data <- model_data[,c(1,2,19:25)]

#Fin variables test

training_fin <- financial_test_data[samp,]
testing_fin <- financial_test_data[-samp,]

model_fin <- train(Log_close_price ~ . , data = training_fin, method="lm") #lm model
predict_lm_fin <- predict(model_fin, testing_fin)
Fin_var_lm_results <- postResample(pred = exp(predict_lm_fin), obs = exp(testing_fin$Log_close_price))

#Operating variables test

training_op <- operating_test_data[samp,]
testing_op <- operating_test_data[-samp,]

model_op <- train(Log_close_price ~ . , data = training_op, method="lm") #lm model
predict_lm_op <- predict(model_op, testing_op)
Op_var_lm_results <- postResample(pred = exp(predict_lm_op), obs = exp(testing_op$Log_close_price))

#Full variable combination test

training <- model_data[samp,]
testing <- model_data[-samp,]

model_all <- train(Log_close_price~., data = training, method="lm") #lm model
predict_lm <- predict(model_all, testing)
All_var_lm_results <- postResample(pred = exp(predict_lm), obs = exp(testing$Log_close_price))


Fin_var_lm_results
Op_var_lm_results
All_var_lm_results

#Stop counting time
end <- Sys.time()
(time <- end - start)

```

Lastly, let us proof the relation through the neural network model too

```{r Separation of variables - Deep Network model test, warnings=FALSE}
# Set seed and start counting time
start <- Sys.time()
set.seed(1908)

financial_test_data <- model_data[,c(1:18,25)]
operating_test_data <- model_data[,c(1,2,19:25)]

#Fin variables test

training_fin <- financial_test_data[samp,]
testing_fin <- financial_test_data[-samp,]

pre_train_test <- as.data.frame(matrix(nrow=nrow(training_fin),ncol=ncol(training_fin)))
pre_train_test[,3:19] <- training_fin[,3:19]
preProcValues_test <- preProcess(pre_train_test, method = "range")
pre_train_test <- predict(preProcValues_test, pre_train_test) 
pre_train_test[,1:2] <- training_fin[,1:2]
col_names_preprocess_fin <- colnames(training_fin)
colnames(pre_train_test) <- col_names_preprocess_fin

pre_test_test <- as.data.frame(matrix(nrow=nrow(testing),ncol=ncol(testing)))
pre_test_test[,3:19] <- testing_fin[,3:19]
preProcValues_test <- preProcess(pre_test_test, method = "range")
pre_test_test <- predict(preProcValues_test, pre_test_test) 
pre_test_test[,1:2] <- testing_fin[,1:2]
colnames(pre_test_test) <- col_names_preprocess_fin

deep_net <- train(Log_close_price ~ ., 
                  data = pre_train_test,
                  method = "neuralnet",
                  trControl = trainControl(method = "cv", number = 10),
                  tuneGrid = deep_grid
)

pred_deep_pre <- predict(deep_net, pre_test_test)

pred_deep <- pred_deep_pre * 
  (max(training_fin$Log_close_price) - min(training_fin$Log_close_price)) + min(training_fin$Log_close_price)

Fin_var_dn_results <- postResample(pred = exp(pred_deep), obs = exp(testing_fin$Log_close_price))

#Operating variables test

training_op <- operating_test_data[samp,]
testing_op <- operating_test_data[-samp,]

pre_train_test <- as.data.frame(matrix(nrow=nrow(training_op),ncol=ncol(training_op)))
pre_train_test[,3:9] <- training_op[,3:9]
preProcValues_test <- preProcess(pre_train_test, method = "range")
pre_train_test <- predict(preProcValues_test, pre_train_test) 
pre_train_test[,1:2] <- training_op[,1:2]
col_names_preprocess_op <- colnames(training_op)
colnames(pre_train_test) <- col_names_preprocess_op

pre_test_test <- as.data.frame(matrix(nrow=nrow(testing),ncol=ncol(testing)))
pre_test_test[,3:9] <- testing_op[,3:9]
preProcValues_test <- preProcess(pre_test_test, method = "range")
pre_test_test <- predict(preProcValues_test, pre_test_test) 
pre_test_test[,1:2] <- testing_op[,1:2]
colnames(pre_test_test) <- col_names_preprocess_op

deep_net <- train(Log_close_price ~ ., 
                  data = pre_train_test,
                  method = "neuralnet",
                  trControl = trainControl(method = "cv", number = 10),
                  tuneGrid = deep_grid
)

pred_deep_pre <- predict(deep_net, pre_test_test)

pred_deep <- pred_deep_pre * 
  (max(training_op$Log_close_price) - min(training_op$Log_close_price)) + min(training_op$Log_close_price)

Op_var_dn_results <- postResample(pred = exp(pred_deep), obs = exp(testing_op$Log_close_price))


#Full variable combination test

training_all <- model_data[samp,]
testing_all <- model_data[-samp,]

pre_train_test <- as.data.frame(matrix(nrow=nrow(training_all),ncol=ncol(training_all)))
pre_train_test[,3:25] <- training_all[,3:25]
preProcValues_test <- preProcess(pre_train_test, method = "range")
pre_train_test <- predict(preProcValues_test, pre_train_test) 
pre_train_test[,1:2] <- training_all[,1:2]
col_names_preprocess_all <- colnames(training_all)
colnames(pre_train_test) <- col_names_preprocess_all

pre_test_test <- as.data.frame(matrix(nrow=nrow(testing),ncol=ncol(testing)))
pre_test_test[,3:25] <- testing_all[,3:25]
preProcValues_test <- preProcess(pre_test_test, method = "range")
pre_test_test <- predict(preProcValues_test, pre_test_test) 
pre_test_test[,1:2] <- testing_all[,1:2]
colnames(pre_test_test) <- col_names_preprocess_all

deep_net <- train(Log_close_price ~ ., 
                  data = pre_train_test,
                  method = "neuralnet",
                  trControl = trainControl(method = "cv", number = 10),
                  tuneGrid = deep_grid
)

pred_deep_pre <- predict(deep_net, pre_test_test)

pred_deep <- pred_deep_pre * 
  (max(training_all$Log_close_price) - min(training_all$Log_close_price)) + min(training_all$Log_close_price)

All_var_dn_results <- postResample(pred = exp(pred_deep), obs = exp(testing_all$Log_close_price))

#Presenting results for Deep Neural Network

Fin_var_dn_results
Op_var_dn_results
All_var_dn_results

#Stopping parallel computing and calculate time
end <- Sys.time()
(time <- end - start)

stopCluster(cluster)

```